\documentclass[journal, a4paper]{IEEEtran}

% some very useful LaTeX packages include:
\usepackage{listings}
\usepackage{amssymb}
%\usepackage{cite}      % Written by Donald Arseneau
                        % V1.6 and later of IEEEtran pre-defines the format
                        % of the cite.sty package \cite{} output to follow
                        % that of IEEE. Loading the cite package will
                        % result in citation numbers being automatically
                        % sorted and properly "ranged". i.e.,
                        % [1], [9], [2], [7], [5], [6]
                        % (without using cite.sty)
                        % will become:
                        % [1], [2], [5]--[7], [9] (using cite.sty)
                        % cite.sty's \cite will automatically add leading
                        % space, if needed. Use cite.sty's noadjust option
                        % (cite.sty V3.8 and later) if you want to turn this
                        % off. cite.sty is already installed on most LaTeX
                        % systems. The latest version can be obtained at:
                        % http://www.ctan.org/tex-archive/macros/latex/contrib/supported/cite/
\usepackage{float}
\usepackage{graphicx}   % Written by David Carlisle and Sebastian Rahtz
                        % Required if you want graphics, photos, etc.
                        % graphicx.sty is already installed on most LaTeX
                        % systems. The latest version and documentation can
                        % be obtained at:
                        % http://www.ctan.org/tex-archive/macros/latex/required/graphics/
                        % Another good source of documentation is "Using
                        % Imported Graphics in LaTeX2e" by Keith Reckdahl
                        % which can be found as esplatex.ps and epslatex.pdf
                        % at: http://www.ctan.org/tex-archive/info/

%\usepackage{psfrag}    % Written by Craig Barratt, Michael C. Grant,
                        % and David Carlisle
                        % This package allows you to substitute LaTeX
                        % commands for text in imported EPS graphic files.
                        % In this way, LaTeX symbols can be placed into
                        % graphics that have been generated by other
                        % applications. You must use latex->dvips->ps2pdf
                        % workflow (not direct pdf output from pdflatex) if
                        % you wish to use this capability because it works
                        % via some PostScript tricks. Alternatively, the
                        % graphics could be processed as separate files via
                        % psfrag and dvips, then converted to PDF for
                        % inclusion in the main file which uses pdflatex.
                        % Docs are in "The PSfrag System" by Michael C. Grant
                        % and David Carlisle. There is also some information
                        % about using psfrag in "Using Imported Graphics in
                        % LaTeX2e" by Keith Reckdahl which documents the
                        % graphicx package (see above). The psfrag package
                        % and documentation can be obtained at:
                        % http://www.ctan.org/tex-archive/macros/latex/contrib/supported/psfrag/

%\usepackage{subfigure} % Written by Steven Douglas Cochran
                        % This package makes it easy to put subfigures
                        % in your figures. i.e., "figure 1a and 1b"
                        % Docs are in "Using Imported Graphics in LaTeX2e"
                        % by Keith Reckdahl which also documents the graphicx
                        % package (see above). subfigure.sty is already
                        % installed on most LaTeX systems. The latest version
                        % and documentation can be obtained at:
                        % http://www.ctan.org/tex-archive/macros/latex/contrib/supported/subfigure/

\usepackage{url}        % Written by Donald Arseneau
                        % Provides better support for handling and breaking
                        % URLs. url.sty is already installed on most LaTeX
                        % systems. The latest version can be obtained at:
                        % http://www.ctan.org/tex-archive/macros/latex/contrib/other/misc/
                        % Read the url.sty source comments for usage information.

%\usepackage{stfloats}  % Written by Sigitas Tolusis
                        % Gives LaTeX2e the ability to do double column
                        % floats at the bottom of the page as well as the top.
                        % (e.g., "\begin{figure*}[!b]" is not normally
                        % possible in LaTeX2e). This is an invasive package
                        % which rewrites many portions of the LaTeX2e output
                        % routines. It may not work with other packages that
                        % modify the LaTeX2e output routine and/or with other
                        % versions of LaTeX. The latest version and
                        % documentation can be obtained at:
                        % http://www.ctan.org/tex-archive/macros/latex/contrib/supported/sttools/
                        % Documentation is contained in the stfloats.sty
                        % comments as well as in the presfull.pdf file.
                        % Do not use the stfloats baselinefloat ability as
                        % IEEE does not allow \baselineskip to stretch.
                        % Authors submitting work to the IEEE should note
                        % that IEEE rarely uses double column equations and
                        % that authors should try to avoid such use.
                        % Do not be tempted to use the cuted.sty or
                        % midfloat.sty package (by the same author) as IEEE
                        % does not format its papers in such ways.

\usepackage{amsmath}    % From the American Mathematical Society
                        % A popular package that provides many helpful commands
                        % for dealing with mathematics. Note that the AMSmath
                        % package sets \interdisplaylinepenalty to 10000 thus
                        % preventing page breaks from occurring within multiline
                        % equations. Use:
%\interdisplaylinepenalty=2500
                        % after loading amsmath to restore such page breaks
                        % as IEEEtran.cls normally does. amsmath.sty is already
                        % installed on most LaTeX systems. The latest version
                        % and documentation can be obtained at:
                        % http://www.ctan.org/tex-archive/macros/latex/required/amslatex/math/



% Other popular packages for formatting tables and equations include:

%\usepackage{array}
% Frank Mittelbach's and David Carlisle's array.sty which improves the
% LaTeX2e array and tabular environments to provide better appearances and
% additional user controls. array.sty is already installed on most systems.
% The latest version and documentation can be obtained at:
% http://www.ctan.org/tex-archive/macros/latex/required/tools/

% V1.6 of IEEEtran contains the IEEEeqnarray family of commands that can
% be used to generate multiline equations as well as matrices, tables, etc.

% Also of notable interest:
% Scott Pakin's eqparbox package for creating (automatically sized) equal
% width boxes. Available:
% http://www.ctan.org/tex-archive/macros/latex/contrib/supported/eqparbox/

% *** Do not adjust lengths that control margins, column widths, etc. ***
% *** Do not use packages that alter fonts (such as pslatex).         ***
% There should be no need to do such things with IEEEtran.cls V1.6 and later.
\usepackage{xcolor}

\lstset{numbers=left, %设置行号位置
        numberstyle=\small, %设置行号大小
        keywordstyle=\color{blue}, %设置关键字颜色
        commentstyle=\color[cmyk]{1,0,1,0}, %设置注释颜色
        frame=single, %设置边框格式
        escapeinside=``, %逃逸字符(1左面的键)，用于显示中文
        breaklines = true, %自动折行
        extendedchars=false, %解决代码跨页时，章节标题，页眉等汉字不显示的问题
        xleftmargin=1em,xrightmargin=0em, aboveskip=1em, %设置边距
        tabsize=2, %设置tab空格数
        showspaces=false %不显示空格
       }
% Your document starts here!
\begin{document}
\begin{titlepage}
\newcommand{\HRule}{\rule{\linewidth}{0.5mm}} % Defines a new command for the horizontal lines, change thickness here

\center % Center everything on the page
 %----------------------------------------------------------------------------------------
%	LOGO SECTION
%----------------------------------------------------------------------------------------

~\\[1cm]
\includegraphics{SCUT.png}\\[2cm] % Include a department/university logo - this will require the graphicx package

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\HRule \\[1cm]
{ \huge \bfseries The Experiment Report of \textit{Machine Learning} }\\[0.6cm] % Title of your document
\HRule \\[2cm]
%----------------------------------------------------------------------------------------
%	HEADING SECTIONS
%----------------------------------------------------------------------------------------


\textsc{\LARGE \textbf{School:} School of Software Engineering}\\[1cm]
\textsc{\LARGE \textbf{Subject:} Software Engineering}\\[2cm]


%----------------------------------------------------------------------------------------
%	AUTHOR SECTION
%----------------------------------------------------------------------------------------

\begin{minipage}{0.4\textwidth}
\begin{flushleft} \large
\emph{Author:}\\
Bin Li % Your name
\par
Liandong Huang\par
Jinqiang Liu
\end{flushleft}
\end{minipage}
~
\begin{minipage}{0.4\textwidth}
\begin{flushright} \large
\emph{Supervisor:} \\
Mingkui Tan % Supervisor's Name
\end{flushright}
\end{minipage}\\[2cm]
~
\begin{minipage}{0.4\textwidth}
\begin{flushleft} \large
\emph{Student ID:}\\
201836661148\par
201830660499\par
201830680169p
\end{flushleft}
\end{minipage}
~
\begin{minipage}{0.4\textwidth}
\begin{flushright} \large
\emph{Grade:} \\
2018 undergraduate
\end{flushright}
\end{minipage}\\[2cm]

% If you don't want a supervisor, uncomment the two lines below and remove the section above
%\Large \emph{Author:}\\
%John \textsc{Smith}\\[3cm] % Your name

%----------------------------------------------------------------------------------------
%	DATE SECTION
%----------------------------------------------------------------------------------------

{\large \today}\\[2cm] % Date, change the \today to a set date if you want to be precise


%----------------------------------------------------------------------------------------

\vfill % Fill the rest of the page with whitespace

\end{titlepage}

% Define document title and author
	\title{Chinese-English Translation Machine Based on Sequence to Sequence Network}
	\maketitle

% Write abstract here
\begin{abstract}
The Seq2Seq model is the most important variant of RNN. This structure is also called Encoder-Decoder model.
\end{abstract}

% Each section begins with a \section{title} command
\section{Introduction}
	% \PARstart{}{} creates a tall first letter for this first paragraph
\PARstart{T}{he} Seq2seq belongs to a kind of encoder-decoder structure. The basic idea of the common encoder-decoder structure is to use two RNNs, one RNN as the encoder and the other RNN as the decoder. The encoder is responsible for compressing the input sequence into a vector of a specified length. This vector can be regarded as the semantics of the sequence. This process is called encoding. The easiest way to obtain the semantic vector is to directly use the hidden state of the last input as the semantic vector C . It is also possible to perform a transformation on the last hidden state to obtain the semantic vector, or to perform a transformation on all the hidden states of the input sequence to obtain the semantic variable.
\par
\begin{figure}[H]
        \begin{center}
        \includegraphics[scale=0.4]{intr_0.png}
        \caption{RNN network}
        \label{fig:ahze1}
        \end{center}
\end{figure}
\par
The decoder is responsible for generating the specified sequence based on the semantic vector. This process is also called decoding, as shown in the figure below. The simplest way is to input the semantic variable obtained by the encoder as the initial state into the RNN of the decoder to obtain the output sequence. It can be seen that the output at the previous moment will be used as the input at the current moment, and the semantic vector C is only used as the initial state to participate in the operation, and the subsequent operations have nothing to do with the semantic vector C.
\begin{figure}[H]
        \begin{center}
        \includegraphics[scale=0.4]{intr_2.png}
        \caption{Semantic vector participates in every process of decoding}
        \label{fig:ahze2}
        \end{center}
\end{figure}
% Main Part
\section{Methods and Theory}
\subsection{The Encoder}
The encoder of a seq2seq network is a RNN that outputs some value for every word from the input sentence. For every input word the encoder outputs a vector and a hidden state, and uses the hidden state for the next input word.
\par
\begin{figure}[H]
        \begin{center}
        \includegraphics[scale=0.6]{encoder.png}
        \caption{Encoder Network}
        \label{fig:ahze23}
        \end{center}
\end{figure}
\par
\subsection{The Attention Decoder}
If only the context vector is passed between the encoder and decoder, that single vector carries the burden of encoding the entire sentence.
\par
Attention allows the decoder network to “focus” on a different part of the encoder’s outputs for every step of the decoder’s own outputs. First we calculate a set of attention weights. These will be multiplied by the encoder output vectors to create a weighted combination. The result (called attn\_applied in the code) should contain information about that specific part of the input sequence, and thus help the decoder choose the right output words.
\par
Calculating the attention weights is done with another feed-forward layer attn, using the decoder’s input and hidden state as inputs. Because there are sentences of all sizes in the training data, to actually create and train this layer we have to choose a maximum sentence length (input length, for encoder outputs) that it can apply to. Sentences of the maximum length will use all the attention weights, while shorter sentences will only use the first few.
\par
\begin{figure}[H]
        \begin{center}
        \includegraphics[scale=0.45]{decoder.png}
        \caption{Attention Decoder Network}
        \label{fig:ahze9}
        \end{center}
\end{figure}
\par



\section{Experiments}
\subsection{Dataset}
Use Chinese and English translation dataset，more translation data sets can be downloaded on this website.
\par
There are a total of 23,610 translation data pairs, and each pair of translation data is on the same line: English on the left, Chinese in the middle, and other attributes information on the right. The separator is tab.
\par
\subsection{Implementation}
\textbf{Loading data files}\par

    Similar to the character encoding used in the character-level RNN tutorials, we will be representing each word in a language as a one-hot vector, or giant vector of zeros except for a single one (at the index of the word). Compared to the dozens of characters that might exist in a language, there are many many more words, so the encoding vector is much larger. We will however cheat a bit and trim the data to only use a few thousand words per language.\par
\begin{figure}[H]
        \begin{center}
        \includegraphics[scale=0.45]{word-encoding.png}
        \caption{word encoding}
        \label{fig:ahze19}
        \end{center}
\end{figure}
The data for this project is a set of many thousands of Chinese to English translation pairs. Download Chinese-English translation dataset.\par

Read the dataset by row and remove the attribute information (only use top-2 split for each line) when constructing the training data pair, otherwise an error will be reported.\par
Split words from the training sentences and construct a comparison table of Chinese and English words in the dataset.\par


~\\[0.3cm]
\textbf{Build a machine translation model}
\par
Chinese-English translation machine is based on sequence to sequence network
\\
1. Build the encoder(Encoder):

\begin{lstlisting}[language=python]
class EncoderRNN(nn.Module):
  def __init__(self,input_size,hidden_size):
    super(EncoderRNN,self).__init__()
    self.hidden_size=hidden_size
    self.embedding=nn.Embedding(input_size, hidden_size)
    self.gru=nn.GRU(hidden_size, hidden_size)
  def forward(self,input,hidden):
    embedded=self.embedding(input).view(1,1,-1)
    output=embedded
    output,hidden=self.gru(output, hidden)
    return output,hidden
  def initHidden(self):
    return torch.zeros(1,1,self.hidden_size,device=device)
\end{lstlisting}
\par

2. Build a decoder based on the attention mechanism(Attention Decoder).
\begin{lstlisting}[language=python]
class AttnDecoderRNN(nn.Module):
  def _init_(self,hidden_size,output_size,dropout_p=0.1,max_length=MAX_LENGTH):
    super(AttnDecoderRNN,self)._init_()
    self.hidden_size=hidden_size
    self.output_size=output_size
    self.dropout_p=dropout_p
    self.max_length=max_length
    self.embedding=nn.Embedding(self.output_size,self.hidden_size)
    self.attn=nn.Linear(self.hidden_size*2,self.max_length)
    self.attn_combine=nn.Linear(self.hidden_size*2,self.hidden_size)
    self.dropout=nn.Dropout(self.dropout_p)
    self.gru=nn.GRU(self.hidden_size,self.hidden_size)
    self.out=nn.Linear(self.hidden_size,self.output_size)
  def forward(self,input,hidden,encoder_outputs):
    embedded=self.embedding(input).view(1,1,-1)
    embedded=self.dropout(embedded)
    attn_weights=F.softmax(
      self.attn(torch.cat((embedded[0],hidden[0]),1)),dim=1)
    attn_applied=torch.bmm(attn_weights.unsqueeze(0),
      encoder_outputs.unsqueeze(0)
    output=torch.cat((embedded[0],attn_applied[0]),1)
    output=self.attn_combine(output).unsqueeze(0)
    output=F.relu(output)
    output, hidden = self.gru(output, hidden)
    output=F.log_softmax(self.out(output[0]), dim=1)
    return output,hidden,attn_weights
  def initHidden(self):
    return torch.zeros(1,1,self.hidden_size,device=device)
\end{lstlisting}
\textbf{Train machine translation model}
\par
The whole training process looks like this:
\begin{itemize}
\item Start a timer
\item Initialize optimizers and criterion
\item Create set of training pairs
\item Then we call train many times and occasionally print the progress
\end{itemize}
\par
Then we call train many times and occasionally print the progress (\% of examples, time so far, estimated time) and average loss.
\begin{figure}[H]
        \begin{center}
        \includegraphics[scale=0.3]{train.png}
        \caption{Training process}
        \label{fig:ahze13}
        \end{center}
\end{figure}
\par
At last we evaluate the trained model by BLEU (The full name is Bilingual Evaluation Understudy). More details can be found in Python Natural Language Toolkit Library (NLTK).


\section{Results}

    \textbf{Loss value}\par
The graph of loss value of the translation model varying with the number of iterations: \par
\begin{figure}[H]
        \begin{center}
        \includegraphics[scale=0.6]{LOSS.png}
        \label{fig:ahze3}
        \end{center}
\end{figure}
           \par
\textbf{Translation results}\par
    We evaluate 100 random sentences from the training set and print out the input, target, and output and calculate the average BLEU score to evaluate the trained model.
\begin{figure}[H]
        \begin{center}
        \includegraphics[scale=0.5]{results.png}
        \caption{the average BLEU score of 100 sentences is 0.976}
        \label{fig:ahze4}
        \end{center}
\end{figure}
           \par

\textbf{Visualizing Attention}\par
A useful property of the attention mechanism is its highly interpretable outputs. Because it is used to weight specific encoder outputs of the input sequence, we can imagine looking where the network is focused most at each time step.
\par
we use matplotlib to see attention output displayed as a matrix, with the columns being input steps and rows being output steps:
\par
\begin{figure}[H]
        \begin{center}
        \includegraphics[scale=0.4]{attention1.png}
        \label{fig:ahze5}
        \end{center}
\end{figure}
\par
\begin{figure}[H]
        \begin{center}
        \includegraphics[scale=0.4]{attention2.png}
        \label{fig:ahze5}
        \end{center}
\end{figure}
\par





\section{Conclusion}
Sequence-to-sequence (seq2seq) model, which is a model with significant effects in natural language processing technology. seq2seq breaks through the traditional fixed-size input problem framework, and it also opens the door for applying classic deep neural network models to sequential tasks such as translation and functional Q\&A.
\par
In this experiment, Due to the small number of experimental data sets, the trained translation model does not perform well on certain sentences. But on most of sentences, the translation model still gives good results.


% Your document ends here!
\end{document}
